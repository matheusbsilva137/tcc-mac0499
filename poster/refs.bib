%% Put here reference entries

@inproceedings{set-membership,
  title={Approximate Membership of Sets : A Survey},
  author={Elias Szabo-Wexler szabowexler},
  year={2014}
}

@inproceedings{cuckoo,
author = {Fan, Bin and Andersen, Dave G. and Kaminsky, Michael and Mitzenmacher, Michael D.},
title = {Cuckoo Filter: Practically Better Than Bloom},
year = {2014},
isbn = {9781450332798},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2674005.2674994},
doi = {10.1145/2674005.2674994},
abstract = {In many networking systems, Bloom filters are used for high-speed set membership tests. They permit a small fraction of false positive answers with very good space efficiency. However, they do not permit deletion of items from the set, and previous attempts to extend "standard" Bloom filters to support deletion all degrade either space or performance.We propose a new data structure called the cuckoo filter that can replace Bloom filters for approximate set membership tests. Cuckoo filters support adding and removing items dynamically while achieving even higher performance than Bloom filters. For applications that store many items and target moderately low false positive rates, cuckoo filters have lower space overhead than space-optimized Bloom filters. Our experimental results also show that cuckoo filters outperform previous data structures that extend Bloom filters to support deletions substantially in both time and space.},
booktitle = {Proceedings of the 10th ACM International on Conference on Emerging Networking Experiments and Technologies},
pages = {75–88},
numpages = {14},
keywords = {bloom filters, cuckoo hashing, compression},
location = {Sydney, Australia},
series = {CoNEXT '14}
}

@ARTICLE{5751342,  author={Tarkoma, Sasu and Rothenberg, Christian Esteve and Lagerspetz, Eemil},  journal={IEEE Communications Surveys \& Tutorials},   title={Theory and Practice of Bloom Filters for Distributed Systems},   year={2012},  volume={14},  number={1},  pages={131-155},  doi={10.1109/SURV.2011.031611.00024}}

@Article{Mosharraf2022,
author={Mosharraf, Sharafat Ibn Mollah
and Adnan, Muhammad Abdullah},
title={Improving lookup and query execution performance in distributed Big Data systems using Cuckoo Filter},
journal={Journal of Big Data},
year={2022},
month={Jan},
day={26},
volume={9},
number={1},
pages={12},
abstract={Performance is a critical concern when reading and writing data from billions of records stored in a Big Data warehouse. We introduce two scopes for query performance improvement. One is to improve the performance of lookup queries after data deletion in Big Data systems that use Eventual Consistency. We propose a scheme to improve lookup performance after data deletion by using Cuckoo Filter. Another scope for improvement is to avoid unnecessary network round-trips for querying in remote nodes in a distributed Big Data cluster when it is known that the nodes do not have requested partition of data. We propose a scheme using probabilistic filters that are looked up before querying remote nodes so that queries resulting in no data can be skipped from passing through the network. We evaluate our schemes with Cassandra using real dataset and show that each scheme can improve performance of lookup queries for up to 2x.},
issn={2196-1115},
doi={10.1186/s40537-022-00563-w},
url={https://doi.org/10.1186/s40537-022-00563-w}
}

@article{bloom,
author = {Bloom, Burton H.},
title = {Space/Time Trade-Offs in Hash Coding with Allowable Errors},
year = {1970},
issue_date = {July 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/362686.362692},
doi = {10.1145/362686.362692},
abstract = {In this paper trade-offs among certain computational factors in hash coding are analyzed. The paradigm problem considered is that of testing a series of messages one-by-one for membership in a given set of messages. Two new hash-coding methods are examined and compared with a particular conventional hash-coding method. The computational factors considered are the size of the hash area (space), the time required to identify a message as a nonmember of the given set (reject time), and an allowable error frequency.The new methods are intended to reduce the amount of space required to contain the hash-coded information from that associated with conventional methods. The reduction in space is accomplished by exploiting the possibility that a small fraction of errors of commission may be tolerable in some applications, in particular, applications in which a large amount of data is involved and a core resident hash area is consequently not feasible using conventional methods.In such applications, it is envisaged that overall performance could be improved by using a smaller core resident hash area in conjunction with the new methods and, when necessary, by using some secondary and perhaps time-consuming test to “catch” the small fraction of errors associated with the new methods. An example is discussed which illustrates possible areas of application for the new methods.Analysis of the paradigm problem demonstrates that allowing a small number of test messages to be falsely identified as members of the given set will permit a much smaller hash area to be used without increasing reject time.},
journal = {Commun. ACM},
month = {jul},
pages = {422–426},
numpages = {5},
keywords = {storage layout, hash addressing, storage efficiency, retrieval trade-offs, hash coding, scatter storage, retrieval efficiency, searching}
}

@article{broder-mitz,
author = {Broder, Andrei and Mitzenmacher, Michael},
year = {2003},
month = {11},
pages = {},
title = {Survey: Network Applications of Bloom Filters: A Survey.},
volume = {1},
journal = {Internet Mathematics},
doi = {10.1080/15427951.2004.10129096}
}

@inproceedings{vahdat,
author = {Reynolds, Patrick and Vahdat, Amin},
title = {Efficient Peer-to-Peer Keyword Searching},
year = {2003},
isbn = {3540403175},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The recent file storage applications built on top of peer-to-peer distributed hash tables lack search capabilities. We believe that search is an important part of any document publication system. To that end, we have designed and analyzed a distributed search engine based on a distributed hash table. Our simulation results predict that our search engine can answer an average query in under one second, using under one kilobyte of bandwidth.},
booktitle = {Proceedings of the ACM/IFIP/USENIX 2003 International Conference on Middleware},
pages = {21–40},
numpages = {20},
keywords = {peer-to-peer, caching, distributed hash table, Bloom filter, search},
location = {Rio de Janeiro, Brazil},
series = {Middleware '03}
}